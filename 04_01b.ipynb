{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "pip install dowhy"
      ],
      "metadata": {
        "id": "KHY7rg8HVKmO"
      },
      "id": "KHY7rg8HVKmO",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "eacef806",
      "metadata": {
        "id": "eacef806"
      },
      "source": [
        "# Example 1 - Applying DoWhy On Simulated Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0fd2c43d",
      "metadata": {
        "id": "0fd2c43d"
      },
      "source": [
        "In this example, we will create dummy dataset using DoWhy library and apply CausalModel on it. Furthermore, we will go through the 4 major steps of Causal AI."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e4f44cca",
      "metadata": {
        "id": "e4f44cca"
      },
      "source": [
        "## Importing the Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "845026fc",
      "metadata": {
        "id": "845026fc"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from dowhy import CausalModel\n",
        "import dowhy.datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5ede9e53",
      "metadata": {
        "id": "5ede9e53"
      },
      "source": [
        "## Loading Sample Data From DoWhy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "77720b86",
      "metadata": {
        "id": "77720b86"
      },
      "outputs": [],
      "source": [
        "data = dowhy.datasets.linear_dataset(\n",
        "            beta=10,\n",
        "            num_common_causes=1,\n",
        "            num_instruments=1,\n",
        "            num_samples=10000,\n",
        "            treatment_is_binary=True)\n",
        "data"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0c0101b7",
      "metadata": {
        "id": "0c0101b7"
      },
      "source": [
        "## Step 1 Of Causal AI: Create a causal model from the data and given graph."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c6c3b1e8",
      "metadata": {
        "id": "c6c3b1e8"
      },
      "outputs": [],
      "source": [
        "model = CausalModel(\n",
        "            data=data[\"df\"],\n",
        "            treatment=data[\"treatment_name\"],\n",
        "            outcome=data[\"outcome_name\"],\n",
        "            graph=data[\"gml_graph\"])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.view_model()"
      ],
      "metadata": {
        "id": "Tdo2l1GZWuTM"
      },
      "id": "Tdo2l1GZWuTM",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "70213973",
      "metadata": {
        "id": "70213973"
      },
      "source": [
        "## Step 2 Of Causal AI: Identify causal effect and return target estimands"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "78b01c8f",
      "metadata": {
        "id": "78b01c8f"
      },
      "outputs": [],
      "source": [
        "identified_estimand = model.identify_effect()\n",
        "print(identified_estimand)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "205e087c",
      "metadata": {
        "id": "205e087c"
      },
      "source": [
        "## Step 3 Of Causal AI: Estimate the target estimand using a statistical method."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b39fc087",
      "metadata": {
        "id": "b39fc087"
      },
      "outputs": [],
      "source": [
        "estimate = model.estimate_effect(identified_estimand,\n",
        "                                 method_name=\"backdoor.propensity_score_matching\")\n",
        "print(estimate)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5930e12a",
      "metadata": {
        "id": "5930e12a"
      },
      "source": [
        "## Step 4 Of Causal AI: Refute the obtained estimate using multiple robustness checks."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4b60bd17",
      "metadata": {
        "id": "4b60bd17"
      },
      "source": [
        "There are different methods supported by DoWhy package to refute (prove or disaprove) obtained results.\n",
        "\n",
        "We will use two most popular methods:\n",
        "\n",
        "1) Adding Random Common Cause\n",
        "\n",
        "2) Using Subset of Data\n",
        "\n",
        "In method 1, randomly-generated cofounder (e.g. independent variable) is added to data to check whether estimation remains almost same or gets changed after data is changed.\n",
        "\n",
        "In method 2, random subset of data is removed to check whether estimation remains almost same after data is reduced.\n",
        "\n",
        "Furthermore, P-Value plays important role in validating whether refute test passes or fails. If P-Value is less than 0.05 then it means test has failed."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "52ca0df8",
      "metadata": {
        "id": "52ca0df8"
      },
      "outputs": [],
      "source": [
        "refute_random_cause = model.refute_estimate(identified_estimand, estimate, method_name=\"random_common_cause\")\n",
        "print(refute_random_cause)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1e66b657",
      "metadata": {
        "id": "1e66b657"
      },
      "outputs": [],
      "source": [
        "refute_data_subset = model.refute_estimate(identified_estimand, estimate, method_name=\"data_subset_refuter\")\n",
        "print(refute_data_subset)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "feb19dbf",
      "metadata": {
        "id": "feb19dbf"
      },
      "source": [
        "As we can see in both refute tests, new effect is almost similar or nearer to estimated effect and p-value is also greater than 0.05 so we can conclude that both refute tests have passed."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python [conda env:tf]",
      "language": "python",
      "name": "conda-env-tf-py"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.16"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}